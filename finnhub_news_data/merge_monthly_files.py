#!/usr/bin/env python3
"""
åˆä½µæŒ‰æœˆä»½åˆ†é–‹çš„æ–°èJSONæª”æ¡ˆåˆ°å–®ä¸€æª”æ¡ˆ
"""

import json
import os
import glob
import argparse
from datetime import datetime

def merge_monthly_files(symbol, output_dir="./sp500_news_urls"):
    """åˆä½µæŒ‡å®šå…¬å¸çš„æ‰€æœ‰æœˆä»½æª”æ¡ˆ"""
    symbol_lower = symbol.lower()
    
    # å°‹æ‰¾æ‰€æœ‰è©²å…¬å¸çš„æœˆä»½æª”æ¡ˆ
    pattern = os.path.join(output_dir, f"{symbol_lower}_*.json")
    monthly_files = sorted(glob.glob(pattern))
    
    if not monthly_files:
        print(f"âŒ æœªæ‰¾åˆ° {symbol} çš„æœˆä»½æª”æ¡ˆ")
        return False
    
    print(f"æ‰¾åˆ° {len(monthly_files)} å€‹ {symbol} çš„æœˆä»½æª”æ¡ˆ:")
    for f in monthly_files:
        print(f"  - {os.path.basename(f)}")
    
    # åˆä½µæ‰€æœ‰æª”æ¡ˆ
    all_news_data = []
    first_file_meta = None
    total_fetched = 0
    total_filtered = 0
    
    for monthly_file in monthly_files:
        try:
            with open(monthly_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if first_file_meta is None:
                # ä¿å­˜ç¬¬ä¸€å€‹æª”æ¡ˆçš„å…ƒæ•¸æ“šä½œç‚ºæ¨¡æ¿
                first_file_meta = {k: v for k, v in data.items() if k != 'news_data'}
            
            if 'news_data' in data:
                all_news_data.extend(data['news_data'])
            
            # ç´¯è¨ˆçµ±è¨ˆæ•¸æ“š
            total_fetched += data.get('total_news_fetched', 0)
            total_filtered += data.get('filtered_out', 0)
            
        except Exception as e:
            print(f"âŒ è®€å– {monthly_file} æ™‚å‡ºéŒ¯: {e}")
            continue
    
    if not first_file_meta or not all_news_data:
        print(f"âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•¸æ“šä¾†åˆä½µ {symbol}")
        return False
    
    # è¨ˆç®—æ—¥æœŸç¯„åœ
    if all_news_data:
        timestamps = [news.get('datetime', 0) for news in all_news_data if news.get('datetime')]
        if timestamps:
            min_timestamp = min(timestamps)
            max_timestamp = max(timestamps)
            from_date = datetime.fromtimestamp(min_timestamp).strftime('%Y-%m-%d')
            to_date = datetime.fromtimestamp(max_timestamp).strftime('%Y-%m-%d')
        else:
            from_date = first_file_meta.get('from_date', 'æœªçŸ¥')
            to_date = first_file_meta.get('to_date', 'æœªçŸ¥')
    else:
        from_date = first_file_meta.get('from_date', 'æœªçŸ¥')
        to_date = first_file_meta.get('to_date', 'æœªçŸ¥')
    
    # å‰µå»ºæœ€çµ‚çš„åˆä½µæª”æ¡ˆ
    final_data = {
        'symbol': symbol,
        'from_date': from_date,
        'to_date': to_date,
        'total_news_fetched': total_fetched,
        'filtered_out': total_filtered,
        'valid_news': len(all_news_data),
        'processed_count': len(all_news_data),
        'generated_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'processed_files': len(monthly_files),
        'source_files': [os.path.basename(f) for f in monthly_files],
        'merged_by': 'merge_monthly_files.py',
        'news_data': all_news_data
    }
    
    # ä¿å­˜åˆä½µå¾Œçš„æª”æ¡ˆ
    final_output = os.path.join(output_dir, f"{symbol_lower}.json")
    
    with open(final_output, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æˆåŠŸåˆä½µ {symbol} çš„ {len(monthly_files)} å€‹æœˆä»½æª”æ¡ˆ")
    print(f"   ç¸½ç²å–: {total_fetched} æ¢ï¼Œéæ¿¾: {total_filtered} æ¢ï¼Œæœ‰æ•ˆ: {len(all_news_data)} æ¢")
    print(f"   æ—¥æœŸç¯„åœ: {from_date} åˆ° {to_date}")
    print(f"   è¼¸å‡ºæª”æ¡ˆ: {final_output}")
    
    # åˆªé™¤åŸå§‹æœˆä»½æª”æ¡ˆ
    for monthly_file in monthly_files:
        os.remove(monthly_file)
        print(f"ğŸ—‘ï¸  å·²åˆªé™¤: {os.path.basename(monthly_file)}")
    
    return True

def main():
    parser = argparse.ArgumentParser(description='åˆä½µæŒ‰æœˆä»½åˆ†é–‹çš„æ–°èJSONæª”æ¡ˆ')
    parser.add_argument('symbol', nargs='?', help='å…¬å¸è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ AAPL, MSFTï¼‰')
    parser.add_argument('--output-dir', default='./sp500_news_urls', help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--all', action='store_true', help='è™•ç†è¼¸å‡ºç›®éŒ„ä¸­æ‰€æœ‰çš„æœˆä»½æª”æ¡ˆ')
    
    args = parser.parse_args()
    
    if args.all:
        # æ‰¾å‡ºæ‰€æœ‰æœ‰æœˆä»½æª”æ¡ˆçš„å…¬å¸
        pattern = os.path.join(args.output_dir, "*_????-??-??.json")
        all_monthly_files = glob.glob(pattern)
        
        if not all_monthly_files:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœˆä»½æª”æ¡ˆ")
            return
        
        # æå–æ‰€æœ‰å…¬å¸ç¬¦è™Ÿ
        symbols = set()
        for f in all_monthly_files:
            basename = os.path.basename(f)
            symbol = basename.split('_')[0].upper()
            symbols.add(symbol)
        
        print(f"æ‰¾åˆ° {len(symbols)} å®¶å…¬å¸çš„æœˆä»½æª”æ¡ˆ: {', '.join(sorted(symbols))}")
        
        for symbol in sorted(symbols):
            print(f"\nè™•ç† {symbol}...")
            merge_monthly_files(symbol, args.output_dir)
    else:
        if not args.symbol:
            parser.error("éœ€è¦æä¾›å…¬å¸ç¬¦è™Ÿï¼Œæˆ–ä½¿ç”¨ --all è™•ç†æ‰€æœ‰æª”æ¡ˆ")
        merge_monthly_files(args.symbol.upper(), args.output_dir)

if __name__ == "__main__":
    main() 