#!/usr/bin/env python3
"""
çµ±è¨ˆS&P 500å…¬å¸æ–°èæ•¸é‡
è¨ˆç®—sp500.jsonä¸­å„å…¬å¸2021-01-01åˆ°2025-05-23çš„æ–°èæ•¸é‡
"""

import os
import sys
import json
import pandas as pd
import time
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from pathlib import Path

# æ·»åŠ finnhub_newsdataç›®éŒ„åˆ°è·¯å¾‘ä»¥ä½¿ç”¨utils
sys.path.append("../finnhub_newsdata")

try:
    from utils import get_company_news, finnhub_client
except ImportError:
    print("âŒ ç„¡æ³•å°å…¥utilsæ¨¡çµ„ï¼Œè«‹ç¢ºèªfinnhub_newsdataç›®éŒ„ä¸­æœ‰utils.py")
    sys.exit(1)

def load_sp500_companies(sp500_file):
    """
    å¾sp500.jsonæ–‡ä»¶ä¸­è®€å–å…¬å¸åˆ—è¡¨
    
    Args:
        sp500_file: sp500.jsonæ–‡ä»¶è·¯å¾‘
    
    Returns:
        list: å…¬å¸è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
    """
    try:
        with open(sp500_file, 'r', encoding='utf-8') as f:
            companies = json.load(f)
        
        if isinstance(companies, list):
            print(f"âœ… æˆåŠŸè®€å– {len(companies)} å®¶S&P 500å…¬å¸")
            return companies
        else:
            print("âŒ sp500.jsonæ ¼å¼ä¸æ­£ç¢ºï¼Œæ‡‰è©²æ˜¯å…¬å¸ä»£ç¢¼æ•¸çµ„")
            return []
            
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {sp500_file}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æéŒ¯èª¤: {e}")
        return []
    except Exception as e:
        print(f"âŒ è®€å–æ–‡ä»¶æ™‚å‡ºéŒ¯: {e}")
        return []

def count_company_news(symbol, from_date, to_date, max_retries=3):
    """
    è¨ˆç®—å–®å€‹å…¬å¸åœ¨æŒ‡å®šæœŸé–“çš„æ–°èæ•¸é‡
    APIä¸€æ¬¡åªèƒ½æŠ“ä¸€å€‹æœˆï¼Œæ‰€ä»¥éœ€è¦åˆ†æœˆè™•ç†
    
    Args:
        symbol: å…¬å¸è‚¡ç¥¨ä»£ç¢¼
        from_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        to_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
    
    Returns:
        int: æ–°èæ•¸é‡ï¼Œå¦‚æœå¤±æ•—è¿”å›None
    """
    try:
        # è½‰æ›æ—¥æœŸ
        start_date = datetime.strptime(from_date, "%Y-%m-%d")
        end_date = datetime.strptime(to_date, "%Y-%m-%d")
        
        total_news_count = 0
        current_date = start_date
        
        # åˆ†æœˆè™•ç†
        while current_date <= end_date:
            # è¨ˆç®—ç•¶æœˆçš„çµæŸæ—¥æœŸ
            month_end = current_date + relativedelta(months=1) - timedelta(days=1)
            if month_end > end_date:
                month_end = end_date
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            month_start_str = current_date.strftime("%Y-%m-%d")
            month_end_str = month_end.strftime("%Y-%m-%d")
            
            # ç²å–ç•¶æœˆæ–°è
            for attempt in range(max_retries):
                try:
                    news_data = get_company_news(symbol, month_start_str, month_end_str)
                    
                    if news_data is not None:
                        month_count = len(news_data)
                        total_news_count += month_count
                        break
                    else:
                        if attempt == max_retries - 1:
                            print(f"    è­¦å‘Š: {symbol} {month_start_str} ç„¡æ–°èæ•¸æ“š")
                        
                except Exception as e:
                    if attempt == max_retries - 1:
                        print(f"    éŒ¯èª¤: ç²å– {symbol} {month_start_str} æ–°èæ™‚å‡ºéŒ¯: {e}")
                    
                if attempt < max_retries - 1:
                    time.sleep(1)
            
            # ç§»åˆ°ä¸‹ä¸€å€‹æœˆ
            current_date = current_date + relativedelta(months=1)
            
            # çŸ­æš«å»¶é²é¿å…APIé »ç‡é™åˆ¶
            time.sleep(0.2)
        
        return total_news_count
        
    except Exception as e:
        print(f"    åš´é‡éŒ¯èª¤: è™•ç† {symbol} æ—¥æœŸç¯„åœæ™‚å‡ºéŒ¯: {e}")
        return None

def save_results(results, output_file):
    """
    ä¿å­˜çµæœåˆ°CSVæ–‡ä»¶
    
    Args:
        results: çµæœåˆ—è¡¨
        output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
    """
    try:
        df = pd.DataFrame(results)
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"âœ… çµæœå·²ä¿å­˜åˆ°: {output_file}")
        
        # é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
        total_companies = len(df)
        successful_companies = len(df[df['news_count'].notna()])
        total_news = df['news_count'].sum()
        
        print(f"\nğŸ“Š çµ±è¨ˆæ‘˜è¦:")
        print(f"  ç¸½å…¬å¸æ•¸: {total_companies}")
        print(f"  æˆåŠŸç²å–æ•¸æ“š: {successful_companies}")
        print(f"  ç¸½æ–°èæ•¸é‡: {int(total_news):,}")
        print(f"  å¹³å‡æ¯å®¶å…¬å¸: {total_news/successful_companies:.1f} æ¢æ–°è")
        
        # é¡¯ç¤ºæ–°èæ•¸é‡æœ€å¤šçš„å‰10å®¶å…¬å¸
        top_companies = df[df['news_count'].notna()].nlargest(10, 'news_count')
        print(f"\nğŸ† æ–°èæ•¸é‡æ’è¡Œæ¦œ (å‰10å):")
        for i, row in top_companies.iterrows():
            print(f"  {row['rank']:2d}. {row['symbol']:5s}: {int(row['news_count']):,} æ¢æ–°è")
            
    except Exception as e:
        print(f"âŒ ä¿å­˜çµæœæ™‚å‡ºéŒ¯: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("=== S&P 500å…¬å¸æ–°èæ•¸é‡çµ±è¨ˆ ===")
    print("æ—¥æœŸç¯„åœ: 2021-01-01 åˆ° 2025-05-23")
    print("=" * 50)
    
    # è¨­å®šåƒæ•¸
    sp500_file = "../sp500.json"
    from_date = "2021-01-01"
    to_date = "2025-05-23"
    output_file = "./sp500_news_count.csv"
    
    # è®€å–S&P 500å…¬å¸åˆ—è¡¨
    companies = load_sp500_companies(sp500_file)
    if not companies:
        return
    
    print(f"\né–‹å§‹çµ±è¨ˆ {len(companies)} å®¶å…¬å¸çš„æ–°èæ•¸é‡...")
    print(f"æ™‚é–“ç¯„åœ: {from_date} åˆ° {to_date}")
    print("-" * 50)
    
    # çµ±è¨ˆçµæœ
    results = []
    successful_count = 0
    failed_count = 0
    
    # è™•ç†æ¯å€‹å…¬å¸
    for i, symbol in enumerate(companies, 1):
        print(f"[{i:3d}/{len(companies):3d}] è™•ç† {symbol}...", end=" ", flush=True)
        
        # ç²å–æ–°èæ•¸é‡
        news_count = count_company_news(symbol, from_date, to_date)
        
        if news_count is not None:
            print(f"âœ… {news_count:,} æ¢æ–°è")
            successful_count += 1
            status = "success"
        else:
            print(f"âŒ å¤±æ•—")
            failed_count += 1
            status = "failed"
        
        # è¨˜éŒ„çµæœ
        results.append({
            'rank': i,
            'symbol': symbol,
            'news_count': news_count,
            'status': status,
            'date_range': f"{from_date} to {to_date}",
            'processed_time': datetime.now().isoformat()
        })
        
        # é¿å…APIé »ç‡é™åˆ¶
        if i % 10 == 0:
            print(f"    å·²è™•ç† {i} å®¶å…¬å¸ï¼Œæš«åœ2ç§’...")
            time.sleep(2)
        else:
            time.sleep(0.5)
    
    print("-" * 50)
    print(f"è™•ç†å®Œæˆï¼æˆåŠŸ: {successful_count}, å¤±æ•—: {failed_count}")
    
    # ä¿å­˜çµæœ
    if results:
        save_results(results, output_file)
    else:
        print("âŒ ç„¡çµæœå¯ä¿å­˜")

if __name__ == "__main__":
    main() 